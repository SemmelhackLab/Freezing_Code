{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36752f46",
   "metadata": {},
   "source": [
    "# Preprocessing of 2 photon imaging(All In One)\n",
    "## Feature:\n",
    "- Ubuntu system\n",
    "- Hsa fish line\n",
    "- Multi-plane imaging(ETL)\n",
    "- Batch processing for all the fish in one folder\n",
    "\n",
    "## Software needed:\n",
    "- ANTs\n",
    "- Fiji\n",
    "- suite2p\n",
    "\n",
    "## Input of the code:\n",
    "- zstack\n",
    "- experimental imaging volume(ETL version)\n",
    "- reference atlas zstack for registration\n",
    "\n",
    "## Objective\n",
    "- Finish the batch processing of all nd2 files to tif files, multi-plane experimental volume will be divided into single plane\n",
    "- Finish the motion correction and segmentation of experimental imaging video of each planes by suite2p\n",
    "- Finish the 2d registration(including prepare the 2d reference by template matching) and 3d registration\n",
    "- Apply registration files onto the segmented ROI coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db631e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scyjava_config\n",
    "from nd2reader import ND2Reader\n",
    "import tifffile\n",
    "import glob\n",
    "import bg_space as bg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843266d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nd2_to_tif(nd2_file, raw_tif_file):\n",
    "    with ND2Reader(nd2_file) as imaging_series:\n",
    "        umperpix = imaging_series.metadata['pixel_microns']\n",
    "        imaging_series_arr = np.array([i for i in imaging_series])\n",
    "        imaging_series_8bit_arr = cv2.convertScaleAbs(imaging_series_arr, alpha=0.07)\n",
    "        imaging_series_mapped_arr = bg.map_stack_to('ilp','ial', imaging_series_8bit_arr) ##refer to bg-space AnatomicalSpace\n",
    "        tifffile.imwrite(raw_tif_file, imaging_series_mapped_arr, imagej=True, resolution=(1/umperpix, 1/umperpix), metadata = imaging_series.metadata)\n",
    "#         tifffile.imwrite(raw_tif_file, imaging_series_mapped_arr, imagej=True)\n",
    "\n",
    "\n",
    "def nd2_to_tif_zscan(nd2_file, raw_tif_file):\n",
    "\n",
    "    with ND2Reader(nd2_file) as imaging_series:\n",
    "        umperpix = imaging_series.metadata['pixel_microns']\n",
    "        imaging_series_arr = np.array([i for i in imaging_series])\n",
    "        imaging_series_8bit_arr = cv2.convertScaleAbs(imaging_series_arr, alpha=0.07)\n",
    "        imaging_series_mapped_arr = bg.map_stack_to('ilp','sal', imaging_series_8bit_arr) ##refer to bg-space AnatomicalSpace\n",
    "        tifffile.imwrite(raw_tif_file, imaging_series_mapped_arr, imagej=True, resolution=(1/umperpix, 1/umperpix), metadata = imaging_series.metadata)\n",
    "#         tifffile.imwrite(raw_tif_file, imaging_series_mapped_arr, imagej=True)\n",
    "\n",
    "\n",
    "def tif_concat(raw_tif_file_list, combined_tif_path):\n",
    "\n",
    "    combined_tif = []\n",
    "    for raw_tif in raw_tif_file_list:\n",
    "        im = tifffile.imread(raw_tif)\n",
    "        im_8bit = cv2.convertScaleAbs(im, alpha=0.07)\n",
    "        combined_tif.append(im_8bit)\n",
    "#     print (combined_tif)\n",
    "    combined_tif = np.concatenate(combined_tif)\n",
    "    print (combined_tif.shape)\n",
    "    tifffile.imwrite(combined_tif_path, combined_tif, imagej=True, resolution=(1/umperpix, 1/umperpix))\n",
    "\n",
    "def create_directory(path):\n",
    "    if os.path.exists(path):\n",
    "        return False\n",
    "    os.makedirs(path)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc1580",
   "metadata": {},
   "source": [
    "# Step 1: batch processing of nd2 files\n",
    "\n",
    "### Firstly you need to check whether the path name of zstack and exp volume's path follow:\n",
    "* /media/semmelhacklab/DRIVE_NAME/BATCH_NAME/DATE/FISH_ID_zscan.nd2\n",
    "* /media/semmelhacklab/DRIVE_NAME/BATCH_NAME/DATE/FISH_ID_exp.nd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb26d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input part\n",
    "#select main directory here\n",
    "main_dir = \"/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/\"\n",
    "total_plane_no = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the nd2 files need to be preprocessed\n",
    "zscan_filelist = glob.glob(main_dir+'/*/*zscan.nd2')\n",
    "exp_filelist = glob.glob(main_dir+'/*/*exp.nd2')\n",
    "\n",
    "# double check\n",
    "print(exp_filelist)\n",
    "print(zscan_filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2506b",
   "metadata": {},
   "source": [
    "## Step 1.1: Convert all nd2 to tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted all exp nd2 files to tif files\n",
    "for fish in exp_filelist:\n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    reg3d_dir = processed_dir+'/registration/reg_3d'\n",
    "    raw_tif_dir = processed_dir + '/raw_tif'\n",
    "    \n",
    "    for directory in [processed_dir, raw_tif_dir,reg3d_dir]:\n",
    "        create_directory(directory)\n",
    "\n",
    "    raw_tif_files = list(map(lambda x: x.replace('nd2', 'tif').replace(main_dir, raw_tif_dir), [fish]))\n",
    "    #convert nd2 to tif\n",
    "    for nd2_file, tif_file  in zip([fish], raw_tif_files):\n",
    "        if os.path.exists(tif_file):\n",
    "            print (nd2_file + \" is already converted to tif, \" + tif_file + \" exists.\")\n",
    "        else:\n",
    "            nd2_to_tif(nd2_file, tif_file)\n",
    "            print (nd2_file + \" is converted to tif.\")\n",
    "\n",
    "            \n",
    "# converted all zstack nd2 files to tif files       \n",
    "zscan_tif_files = list(map(lambda x: x.replace('nd2', 'tif'), zscan_filelist))\n",
    "\n",
    "for nd2_file, tif_file  in zip(zscan_filelist,zscan_tif_files):\n",
    "    if os.path.exists(tif_file):\n",
    "        print (nd2_file + \" is already converted to tif, \" + tif_file + \" exists.\")\n",
    "    else:\n",
    "        nd2_to_tif_zscan(nd2_file, tif_file)\n",
    "        print (nd2_file + \" is converted to tif.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86298f",
   "metadata": {},
   "source": [
    "## Step 1.2: Split plane in the exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5090b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fish in exp_filelist:\n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir + date_str + '/processed/'+fish_str\n",
    "    raw_tif_dir = processed_dir + '/raw_tif'\n",
    "    raw_tif = list(map(lambda x: x.replace('nd2', 'tif').replace(main_dir, raw_tif_dir), [fish]))[0]\n",
    "    print(raw_tif)\n",
    "    with tifffile.TiffFile('raw_tif') as tif:\n",
    "        raw_tif_array = tif.asarray()\n",
    "        metadata = tif.imagej_metadata\n",
    "        umperpix = metadata['pixel_microns']\n",
    "        \n",
    "    for p_i in range(0,total_plane_no):\n",
    "        locals()['raw_tif_array_'+ str(p_i)]= raw_tif_array[range(p_i,raw_tif_array.shape[0],total_plane_no),:]\n",
    "        splited_tif_path = raw_tif[:-4]+'_plane'+str(p_i)+'.tif'\n",
    "        tifffile.imwrite(splited_tif_path,  locals()['raw_tif_array_'+ str(p_i)], imagej=True, resolution=(1/umperpix, 1/umperpix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5ebb1",
   "metadata": {},
   "source": [
    "# Step 2: Suite2p motion correction and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import suite2p\n",
    "from suite2p import run_s2p \n",
    "from suite2p import default_ops\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d957412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input part\n",
    "main_dir = \"/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/\"\n",
    "trial_no = 48\n",
    "plane_no = 9\n",
    "fpv = 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4e8ba",
   "metadata": {},
   "source": [
    "## Step 2.1: Run suite2p to do motion correction and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dff804",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fish_dir in glob.glob(main_dir+'*/processed/*'):\n",
    "\n",
    "    fish_str = fish_dir.split('/')[-1]\n",
    "    date_str = fish_dir.split('/')[-3]\n",
    "    fish = main_dir+date_str+'/'+fish_str+'_exp.nd2'\n",
    "    processed_dir = fish_dir\n",
    "    raw_tif_dir = processed_dir + '/raw_tif'\n",
    "    registered_tif_dir = processed_dir+'/processed_suite2p'\n",
    "    create_directory(registered_tif_dir)\n",
    "\n",
    "    file_list = list(set(glob.glob(raw_tif_dir+'/*exp_plane*.tif'))-set(glob.glob(raw_tif_dir+'/*exp_plane0*.tif')))\n",
    "    print(file_list)\n",
    "\n",
    "\n",
    "    for file_dir in file_list:\n",
    "        temp_raw_tif_dir = raw_tif_dir+'/'+file_dir[-10:-4]\n",
    "        save_dir = registered_tif_dir+ '/'+file_dir[-10:-4]\n",
    "        comb_registered_tif_dir = save_dir + '/combined_registered'\n",
    "        create_directory(temp_raw_tif_dir)\n",
    "        create_directory(save_dir)\n",
    "        create_directory(comb_registered_tif_dir)\n",
    "\n",
    "\n",
    "        shutil.move(file_dir,temp_raw_tif_dir+'/'+file_dir.split(\"/\")[-1])\n",
    "\n",
    "        ops = default_ops()\n",
    "        ops['batch_size'] = 200\n",
    "        ops['roidetect'] = True\n",
    "        ops['reg_tif'] = True\n",
    "        ops['save_folder'] = save_dir\n",
    "        ops['nimg_init'] = 300\n",
    "        \n",
    "##########################\n",
    "### check the segmentation performance of this combo by Suite2p GUI\n",
    "        ops['classifier_path'] = 'test_suite2p_classifier.npy'\n",
    "##########################\n",
    "\n",
    "\n",
    "        db = {\n",
    "            'h5py': [],\n",
    "            'h5py_key': 'data',\n",
    "            'look_one_level_down': False,\n",
    "            'data_path': [temp_raw_tif_dir],                     \n",
    "            'subfolders': [], \n",
    "            'reg_tif': True\n",
    "            }\n",
    "\n",
    "        opsEnd=run_s2p(ops=ops,db=db)\n",
    "\n",
    "##########################\n",
    "### check whether concatnation work now\n",
    "        # concatenate s2p output\n",
    "        if os.path.exists(comb_registered_tif_dir + '/combined_reg.tif'):\n",
    "            print ('registered stack combined.')\n",
    "        else:\n",
    "            print ('now the registered stack is being combined')\n",
    "            reg_tif_list = sorted(glob.glob(save_dir + '/plane0/reg_tif/**.tif'), key=os.path.getmtime)\n",
    "            print(reg_tif_list)\n",
    "            tif_concat(reg_tif_list, comb_registered_tif_dir + '/combined_reg.tif')    \n",
    "##########################\n",
    "        print('completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866be21",
   "metadata": {},
   "source": [
    "## Step 2.2: Organize segmented information into deltaF trace csv and cell info csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fish_dir in glob.glob(main_dir+'*/processed/*'):\n",
    "    fish_str = fish_dir.split('/')[-1]\n",
    "    date_str = fish_dir.split('/')[-3]\n",
    "    processed_dir = fish_dir\n",
    "    registered_tif_dir = processed_dir+'/processed_suite2p'\n",
    "    for plane_i in range(1,plane_no+1):\n",
    "        temp_dir = registered_tif_dir +'/plane'+str(plane_i)\n",
    "        deltaF_dir = temp_dir +'/DeltaF_F'\n",
    "        create_directory(deltaF_dir)\n",
    "        print(deltaF_dir)\n",
    "        F = np.load(temp_dir + '/plane0/F.npy', allow_pickle=True)\n",
    "        stat = np.load(temp_dir+'/plane0/stat.npy', allow_pickle=True)\n",
    "        iscell = np.load(temp_dir+'/plane0/iscell.npy', allow_pickle=True)\n",
    "        \n",
    "        cell_idx = []\n",
    "        df_cell_info = pd.DataFrame(columns = ['ROI_id','centroid_x','centroid_y','npix','radius'])\n",
    "        \n",
    "        for ROI_i in np.where(iscell[:,1]>0.2)[0]:\n",
    "            if stat[ROI_i]['npix']>40 and stat[ROI_i]['npix']<300:\n",
    "                temp_x = df_cell_info.shape[0]\n",
    "                df_cell_info.loc[temp_x,:] = [ROI_i,stat[ROI_i]['med'][1],stat[ROI_i]['med'][0],stat[ROI_i]['npix'],stat[ROI_i]['radius']]\n",
    "                cell_idx.append(ROI_i)\n",
    "        \n",
    "        df_cell_info.to_csv(deltaF_dir +'/cell_info_'+fish_str+'_plane'+str(plane_i)+'.csv',index=False)\n",
    "        \n",
    "        \n",
    "        for trial_i in range(1,trial_no+1):\n",
    "            temp_filename = fish_str+'_Trial'+str(trial_i)+'.csv'\n",
    "            np_temp_F = F[cell_idx,fpv*trial_i-fpv:fpv*trial_i]\n",
    "            np_temp_df_f = np.zeros(shape=np_temp_F.shape)\n",
    "            for cell_i in range(0,np_temp_F.shape[0]):\n",
    "                temp_baseline = np.average(np_temp_F[cell_i,15:27])\n",
    "                if temp_baseline!=0:\n",
    "                    temp_trace = np_temp_F[cell_i,:]\n",
    "                    np_temp_df_f[cell_i,:] = (temp_trace-temp_baseline)/temp_baseline\n",
    "           \n",
    "                   \n",
    "            temp_df_f = pd.DataFrame(np_temp_df_f)\n",
    "            temp_df_f['ROI_id'] = cell_idx\n",
    "            temp_df_f.to_csv(deltaF_dir+'/'+temp_filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07de547",
   "metadata": {},
   "source": [
    "# Step 3: Registration\n",
    "## Step 3.1: convert all zstack tif files to nrrd files in reg3d folder (By Fiji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej\n",
    "# Path to your Fiji installation that includes\n",
    "fiji_path = 'fiji'\n",
    "#fiji_path = 'C:\\\\Users\\\\Semmelhack Lab\\\\Downloads\\\\fiji-win64\\\\Fiji'\n",
    "# Initialize Fiji\n",
    "scyjava_config.add_options('-Xmx16g') ### use 8g or ram\n",
    "ij = imagej.init(fiji_path)\n",
    "ij.getVersion()\n",
    "ij.ui().showUI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input part\n",
    "main_dir = \"/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_to_nrrd = \"\"\"\n",
    "#@ String tif_path\n",
    "#@ String nrrd_path\n",
    "setBatchMode(true);\n",
    "open(tif_path);\n",
    "run(\"Nrrd ... \", \"nrrd=\" + nrrd_path);\n",
    "run(\"Close All\");\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for tif_file in zscan_tif_files:\n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    reg3d_dir = processed_dir+'/registration/reg_3d/'\n",
    "    nrrd_file = reg3d_dir++fish_str+'_zscan.nrrd'\n",
    "    if os.exist.path(nrrd_file):\n",
    "        print(nrrd_file+' already existed!')\n",
    "    else:\n",
    "        args = {\n",
    "            'tif_path': tif_file,\n",
    "            'nrrd_path': nrrd_file\n",
    "        }\n",
    "        ij.py.run_script('ijm', tif_to_nrrd, args)\n",
    "        print(nrrd_file+' is converted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca085b79",
   "metadata": {},
   "source": [
    "## Step 3.2: Create the 2d reference image from z stack by template matching\n",
    "\n",
    "### Remember to manual check the reference image's accuracy in this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a10302b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccaabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Part\n",
    "main_dir = \"/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/\"\n",
    "plane_no = 9\n",
    "width = 512\n",
    "\n",
    "##########################\n",
    "### Rember to check whether resize or not work better\n",
    "resize = int(509.12/339.41*width)\n",
    "# resize = int(width)\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for fish in zscan_tif_files:\n",
    "    \n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    processed_suite2p_dir = processed_dir + '/processed_suite2p'\n",
    "    \n",
    "    for p_i in range(1,plane_no+1):\n",
    "        directory_2d = processed_dir+'/registration/reg_2d/plane'+str(p_i)\n",
    "        create_directory(directory_2d)\n",
    "##########################\n",
    "### Remember to check whether the reading issue is solved in ubuntu system\n",
    "        registered_tif0_dir = processed_suite2p_dir+'/plane'+str(p_i)+'/plane0/reg_tif/file1200_chan0.tif'\n",
    "        registered_tif0 =  tifffile.imread(registered_tif0_dir)\n",
    "#         avg_combined_reg = np.mean(combined_reg,axis = 0)\n",
    "        avg_combined_reg_8bit = cv.convertScaleAbs(registered_tif0, alpha=0.7)\n",
    "##########################\n",
    "        tifffile.imwrite(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg.tif', avg_combined_reg_8bit)\n",
    "        \n",
    "        temp_image = Image.open(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg.tif')\n",
    "        resized_image = temp_image.resize((resize, resize), Image.ANTIALIAS)\n",
    "        resized_image.save(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg_resized.tif')\n",
    "        \n",
    "        img2 = tifffile.imread(fish)\n",
    "        template =  cv.imread(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg_resized.tif',0)\n",
    "        \n",
    "        \n",
    "        plt.imshow(template)\n",
    "        plt.show()\n",
    "        w, h = template.shape[::-1]\n",
    "        method = cv.TM_CCOEFF_NORMED\n",
    "        # top_left = np.array(shape=(img2.shape[0],2))\n",
    "        corr_score= []\n",
    "        top_left_list = []\n",
    "        for i in range(0,img2.shape[0]):\n",
    "            img = img2[i].copy()\n",
    "            res = cv.matchTemplate(img,template,method)\n",
    "            min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "            top_left = max_loc\n",
    "            corr_score.append(max_val)\n",
    "            top_left_list.append(top_left)\n",
    "\n",
    "        plt.plot(corr_score)\n",
    "        plt.title('Plane'+str(p_i)+' '+fish_str)\n",
    "        plt.show()\n",
    "        temp_slice_no = np.argmax(corr_score)\n",
    "    #     temp_slice_no = np.argmax(corr_score[80:])+80\n",
    "        print(temp_slice_no+1)\n",
    "        print(top_left_list[temp_slice_no])\n",
    "        tifffile.imwrite(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_zstack_slice.tif',img2[temp_slice_no,:,:])\n",
    "        np.save(directory_2d+'/slice_no.npy',np.array(temp_slice_no+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b996955d",
   "metadata": {},
   "source": [
    "### Step 3.2+: If there are errors when checking the reference, then use the code below to correct manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input part \n",
    "fish = '/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/20230312/F6_20_00_zscan.tif'\n",
    "p_i = 9 # plane No.\n",
    "temp_slice_no = 156 # Correct reference z position slice No.(display in fiji,need to -1 when saving the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_str = fish.split('/')[-1][:8]\n",
    "date_str = fish.split('/')[-2]\n",
    "processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "processed_suite2p_dir = processed_dir + '/processed_suite2p'\n",
    "\n",
    "\n",
    "directory_2d = processed_dir+'/registration/reg_2d/plane'+str(p_i)\n",
    "create_directory(directory_2d)\n",
    "\n",
    "##########################\n",
    "### Remember to check whether the reading issue is solved in ubuntu system\n",
    "registered_tif0_dir = processed_suite2p_dir+'/plane'+str(p_i)+'/plane0/reg_tif/file1000_chan0.tif'\n",
    "registered_tif0 =  tifffile.imread(registered_tif0_dir)\n",
    "#         avg_combined_reg = np.mean(combined_reg,axis = 0)\n",
    "avg_combined_reg_8bit = cv.convertScaleAbs(registered_tif0, alpha=0.7)\n",
    "##########################\n",
    "\n",
    "tifffile.imwrite(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg.tif', avg_combined_reg_8bit)\n",
    "\n",
    "temp_image = Image.open(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg.tif')\n",
    "resized_image = temp_image.resize((resize, resize), Image.ANTIALIAS)\n",
    "resized_image.save(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg_resized.tif')\n",
    "temp_image.close()\n",
    "\n",
    "img2 = tifffile.imread(fish)\n",
    "template =  cv.imread(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_avg_combined_reg_resized.tif',0)\n",
    "plt.imshow(template)\n",
    "plt.show()\n",
    "w, h = template.shape[::-1]\n",
    "method = cv.TM_CCOEFF_NORMED\n",
    "# top_left = np.array(shape=(img2.shape[0],2))\n",
    "corr_score= []\n",
    "top_left_list = []\n",
    "for i in range(0,img2.shape[0]):\n",
    "    img = img2[i].copy()\n",
    "    res = cv.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    top_left = max_loc\n",
    "    corr_score.append(max_val)\n",
    "    top_left_list.append(top_left)\n",
    "\n",
    "plt.plot(corr_score)\n",
    "plt.title('Plane'+str(p_i)+' '+fish_str)\n",
    "plt.show()\n",
    "\n",
    "print(temp_slice_no)\n",
    "print(top_left_list[temp_slice_no-1])\n",
    "tifffile.imwrite(directory_2d+'/'+fish_str+'_'+'plane'+str(p_i)+'_zstack_slice.tif',img2[temp_slice_no-1,:,:])\n",
    "np.save(directory_2d+'/slice_no.npy',np.array(temp_slice_no))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44d25d",
   "metadata": {},
   "source": [
    "## Step 3.3: 2d Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e65d7",
   "metadata": {},
   "source": [
    "Test done in hpc(for reference when writing code):\n",
    "```\n",
    "command=\"antsRegistration\"\n",
    "# command=\"python --version\"\n",
    "os.system(\"gnome-terminal -e 'bash -c \\\"\"+command+\";bash\\\"'\") # if you want the terminal to stay open and be in a bash shell \n",
    "os.system(\"gnome-terminal -e 'bash -c \\\"\"+command+\"; sleep 10\\\" '\") #if you need a terminal to stay open for 10s\n",
    "os.system(\"gnome-terminal -e 'bash -c \\\"\"+command+\"\\\" '\") # if you want to close the terminal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0841fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Part\n",
    "main_dir = \"/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/\"\n",
    "plane_no = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ef2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for fish in zscan_tif_files:\n",
    "    \n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    \n",
    "    for p_i in range(1,plane_no+1):\n",
    "        directory_2d = processed_dir+'/registration/reg_2d/plane'+str(p_i)\n",
    "        \n",
    "        sh_reg2d_path = directory_2d+'/reg2d.sh'\n",
    "        # write 2d registration shell script for each plane\n",
    "        with open(sh_reg2d_path,'w') as f:\n",
    "            s = 'directory_2d='+directory_2d+'\\n'+\\\n",
    "                'fish='+fish_str+'\\n'+\\\n",
    "                'plane=plane'+str(p_i)+'\\n'+\\\n",
    "                'reference=${directory_2d}/${fish}_${plane}_zstack_slice.tif\\n'+\\\n",
    "                'moving_file=${directory_2d}/${fish}_${plane}_avg_combined_reg_resized.tif\\n'+\\\n",
    "                'prefix=${directory_2d}/${fish}_${plane}_2d_output_\\n'+\\\n",
    "                'warped_file=${prefix}warped.tif\\n\\n\\n'+\\\n",
    "                'antsRegistration --verbose 1 \\\\\\n\\\n",
    "                --dimensionality 2 \\\\\\n\\\n",
    "                --float \\\\\\n\\\n",
    "                --collapse-output-transforms 1 \\\\\\n\\\n",
    "                --output [$prefix,${prefix}Warped.nii.gz,${prefix}InverseWarped.nii.gz ] \\\\\\n\\\n",
    "                --interpolation Linear \\\\\\n\\\n",
    "                --winsorize-image-intensities [ 0.005,0.995 ] \\\\\\n\\\n",
    "                --initial-moving-transform [ $reference,$moving_file,1 ] \\\\\\n\\\n",
    "                --transform Rigid[ 0.1 ] \\\\\\n\\\n",
    "                --metric MI[ $reference,$moving_file,1,32,Regular,0.25 ] \\\\\\n\\\n",
    "                --convergence [ 1000x500x250x0,1e-8,15 ] \\\\\\n\\\n",
    "                --shrink-factors 12x8x4x2 \\\\\\n\\\n",
    "                --smoothing-sigmas 4x3x2x1vox \\\\\\n\\\n",
    "                --transform Affine[ 0.1 ] \\\\\\n\\\n",
    "                --metric MI[ $reference,$moving_file,1,32,Regular,0.25 ] \\\\\\n\\\n",
    "                --convergence [ 1000x500x250x0,1e-8,15 ] \\\\\\n\\\n",
    "                --shrink-factors 12x8x4x2 \\\\\\n\\\n",
    "                --smoothing-sigmas 4x3x2x1vox\\n\\n\\n'+\\\n",
    "                'antsApplyTransforms --verbose 1 \\\\\\n\\\n",
    "                --dimensionality 2 \\\\\\n\\\n",
    "                --float \\\\\\n\\\n",
    "                --interpolation WelchWindowedSinc \\\\\\n\\\n",
    "                --input $moving_file \\\\\\n\\\n",
    "                --reference-image $reference \\\\\\n\\\n",
    "                --output $warped_file \\\\\\n\\\n",
    "                --transform ${prefix}0GenericAffine.mat'\n",
    "            f.write(s)\n",
    "\n",
    "        # run the shell script above\n",
    "        command=\"sh \"+sh_reg2d_path\n",
    "        os.system(\"gnome-terminal -e 'bash -c \\\"\"+command+\"; sleep 30\\\" '\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a6687",
   "metadata": {},
   "source": [
    "## Step 3.4: 3d Registration(takes around 0.5hr per fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32bfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Part\n",
    "main_dir = \"/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/\"\n",
    "reference_path = \"/media/semmelhacklab/P2_YX/registration_code_HSA/T_AVG_H2BGCaMP.nrrd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for fish in zscan_tif_files:\n",
    "    \n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    directory_3d = processed_dir+'/registration/reg_3d'\n",
    "    \n",
    "    sh_reg3d_path = directory_3d+'/reg3d.sh'\n",
    "\n",
    "    # write 3d registration shell script for each fish\n",
    "    with open(sh_reg3d_path,'w') as f:\n",
    "        s = 'reference='+reference_path+'\\n'+\\\n",
    "            'directory_3d='+directory_3d+'\\n'+\\\n",
    "            'fish='+fish_str+'\\n'+\\\n",
    "            'moving_file=${directory_3d}/${fish}_zscan.nrrd\\n'+\\\n",
    "            'prefix=${directory_3d}/${fish}_reg3d_\\n'+\\\n",
    "            'warped_file=${prefix}zscan_wrapped.nrrd\\n\\n\\n'+\\\n",
    "            'antsRegistration --verbose 1 \\\\\\n\\\n",
    "            --dimensionality 3 \\\\\\n\\\n",
    "            --float \\\\\\n\\\n",
    "            --collapse-output-transforms 1 \\\\\\n\\\n",
    "            --output [$prefix,${prefix}Warped.nii.gz,${prefix}InverseWarped.nii.gz ] \\\\\\n\\\n",
    "            --interpolation Linear \\\\\\n\\\n",
    "            --winsorize-image-intensities [ 0.005,0.995 ] \\\\\\n\\\n",
    "            --initial-moving-transform [ $reference,$moving_file,1 ] \\\\\\n\\\n",
    "            --transform Rigid[ 0.1 ] \\\\\\n\\\n",
    "            --metric MI[ $reference,$moving_file,1,32,Regular,0.25 ] \\\\\\n\\\n",
    "            --convergence [ 1000x500x250x0,1e-6,10 ] \\\\\\n\\\n",
    "            --shrink-factors 12x8x4x2 \\\\\\n\\\n",
    "            --smoothing-sigmas 4x3x2x1vox \\\\\\n\\\n",
    "            --transform Affine[ 0.1 ] \\\\\\n\\\n",
    "            --metric MI[ $reference,$moving_file,1,32,Regular,0.25 ] \\\\\\n\\\n",
    "            --convergence [ 1000x500x250x0,1e-6,10 ] \\\\\\n\\\n",
    "            --shrink-factors 12x8x4x2 \\\\\\n\\\n",
    "            --smoothing-sigmas 4x3x2x1vox \\\\\\n\\\n",
    "            --transform SyN[ 0.1,3,0 ] \\\\\\n\\\n",
    "            --metric MI[ $reference,$moving_file,1,32] \\\\\\n\\\n",
    "            --convergence [ 100x100x70x50x0,1e-6,10 ] \\\\\\n\\\n",
    "            --shrink-factors 10x6x4x2x1 \\\\\\n\\\n",
    "            --smoothing-sigmas 5x3x2x1x0vox\\n\\n\\n'+\\\n",
    "            'antsApplyTransforms --verbose 1 \\\\\\n\\\n",
    "            --dimensionality 3 \\\\\\n\\\n",
    "            --float \\\\\\n\\\n",
    "            --interpolation WelchWindowedSinc \\\\\\n\\\n",
    "            --input $moving_file \\\\\\n\\\n",
    "            --reference-image $reference \\\\\\n\\\n",
    "            --output $warped_file \\\\\\n\\\n",
    "            --transform ${prefix}1Warp.nii.gz \\\\\\n\\\n",
    "            --transform ${prefix}0GenericAffine.mat'\n",
    "        f.write(s)\n",
    "        \n",
    "    # run the shell script above\n",
    "    command=\"sh \"+sh_reg3d_path\n",
    "    os.system(\"gnome-terminal -e 'bash -c \\\"\"+command+\"; sleep 30\\\" '\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6fcc8",
   "metadata": {},
   "source": [
    "## Step 3.5: (No code but Important!!!) Check the registration performance of warped file One By One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945983a8",
   "metadata": {},
   "source": [
    "# Step 4: Apply transformation files on all the segmented neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e2da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input part\n",
    "main_dir = \"/media/semmelhacklab/P2_YX/LCr_UV_HSA_Lum_Low/\"\n",
    "\n",
    "##########################\n",
    "### Rember to check whether resize or not work better\n",
    "resize_ratio = 509.12/339.41\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1af589",
   "metadata": {},
   "source": [
    "## Step 4.1: organize the coordinates of the segmented neurons from each plane and save in reg2d folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for fish in zscan_tif_files:\n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    processed_suite2p_dir = processed_dir + '/processed_suite2p'\n",
    "    \n",
    "    for p_i in range(1,plane_no+1):\n",
    "        directory_2d = processed_dir+'/registration/reg_2d/plane'+str(p_i)\n",
    "        slice_no = np.load(directory_2d+'/slice_no.npy')\n",
    "        path_cell_info = processed_suite2p_dir+'/plane'+str(p_i)+'/DeltaF_F/cell_info_'+fish_str+'_plane'+str(p_i)+'.csv')\n",
    "        df_cell_info = pd.read_csv(path_cell_info)\n",
    "        \n",
    "        df_coor = pd.DataFrame(columns = ['x','y','z','t','label'])\n",
    "        df_coor.x = df_cell_info.centroid_x*resize_ratio\n",
    "        df_coor.y = df_cell_info.centroid_y*resize_ratio\n",
    "        df_coor.z = slice_no\n",
    "        df_coor.t = 0\n",
    "        df_coor.label = df_cell_info.ROI_id\n",
    "        \n",
    "        path_toreg = directory_2d+'/'+fish_str+'_plane'+str(p_i)+'_coordinates.csv'\n",
    "        df_coor.to_csv(path_toreg,index=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a643107",
   "metadata": {},
   "source": [
    "## Step 4.2: Apply reg2d transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939cc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for fish in zscan_tif_files:\n",
    "    \n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    \n",
    "    for p_i in range(1,plane_no+1):\n",
    "        directory_2d = processed_dir+'/registration/reg_2d/plane'+str(p_i)\n",
    "        \n",
    "        sh_applyreg2d_path = directory_2d+'/ApplyToROIs_reg2d.sh'\n",
    "        # write 2d ApplyToROIs shell script for each plane\n",
    "        with open(sh_applyreg2d_path,'w') as f:\n",
    "            s = 'directory_2d='+directory_2d+'\\n'+\\\n",
    "                'fish='+fish_str+'\\n'+\\\n",
    "                'plane=plane'+str(p_i)+'\\n'+\\\n",
    "                'prefix2d=${directory_2d}/${fish}_${plane}_2d_output_\\n'+\\\n",
    "                'prefix_csv=${directory_2d}/${fish}_${plane}_coordinates\\n\\n\\n'+\\\n",
    "                'antsApplyTransformsToPoints -d 2 -i ${prefix_csv}.csv -o ${prefix_csv}_reg2d.csv -t [${prefix2d}0GenericAffine.mat,1]'\n",
    "            f.write(s)\n",
    "\n",
    "        # run the shell script above\n",
    "        command=\"sh \"+sh_applyreg2d_path\n",
    "        os.system(\"gnome-terminal -e 'bash -c \\\"\"+command+\"; sleep 3\\\" '\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba54f28",
   "metadata": {},
   "source": [
    "## Step 4.3: Transform the unit of the registered 2d coordinates as microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa19565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input part\n",
    "ratio_pixel_to_micron = 509.12/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = glob.glob(main_dir+'/*/processed/*/registration/reg_2d/*/F*_reg2d.csv')\n",
    "\n",
    "for temp_dir in dir_list:\n",
    "    temp_reg2d_csv = pd.read_csv(temp_dir)\n",
    "    temp_reg2d_csv.x = temp_reg2d_csv.x*ratio_pixel_to_micron\n",
    "    temp_reg2d_csv.y = temp_reg2d_csv.y*ratio_pixel_to_micron\n",
    "    temp_reg2d_csv.to_csv(temp_dir[:-4]+'_micron.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10772c",
   "metadata": {},
   "source": [
    "## Step 4.4: Apply reg3d transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f113f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for fish in zscan_tif_files:\n",
    "    \n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    directory_3d = processed_dir+'/registration/reg_3d'\n",
    "    \n",
    "    for p_i in range(1,plane_no+1):\n",
    "        directory_2d = processed_dir+'/registration/reg_2d/plane'+str(p_i)\n",
    "        sh_applyreg3d_path = directory_2d+'/ApplyToROIs_reg3d.sh'\n",
    "\n",
    "        # write 3d ApplyToROIs shell script for each fish\n",
    "        with open(sh_applyreg3d_path,'w') as f:\n",
    "            s = 'directory_3d='+directory_3d+'\\n'+\\\n",
    "                'fish='+fish_str+'\\n'+\\\n",
    "                'prefix3d=${directory_3d}/${fish}_reg3d_\\n'+\\\n",
    "                'prefix_csv=${directory_2d}/${fish}_${plane}_coordinates\\n\\n\\n'+\\\n",
    "                'antsApplyTransformsToPoints -d 3 -i ${prefix_csv}_reg2d_micron.csv -o ${prefix_csv}_reg3d.csv -t [${prefix3d}0GenericAffine.mat,1] -t ${prefix3d}1InverseWarp.nii.gz'\n",
    "            f.write(s)\n",
    "\n",
    "        # run the shell script above\n",
    "        command=\"sh \"+sh_applyreg3d_path\n",
    "        os.system(\"gnome-terminal -e 'bash -c \\\"\"+command+\"; sleep 3\\\" '\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72859123",
   "metadata": {},
   "source": [
    "## Step 4.5: Save the registered coordinate information back into cell_info csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscan_tif_files = glob.glob(main_dir+'/*/*zscan.tif')\n",
    "for fish in zscan_tif_files:\n",
    "    fish_str = fish.split('/')[-1][:8]\n",
    "    date_str = fish.split('/')[-2]\n",
    "    processed_dir = main_dir +date_str+ '/processed/'+fish_str\n",
    "    processed_suite2p_dir = processed_dir + '/processed_suite2p'\n",
    "    \n",
    "    for p_i in range(1,plane_no+1):\n",
    "        path_csv_reg3d = processed_dir+'/registration/reg_2d/plane'+str(p_i)+'/'+fish_str+'_plane'+str(p_i)+'_coordinates_reg3d.csv'\n",
    "        df_csv_reg3d = pd.read_csv(path_csv_reged)\n",
    "        \n",
    "        path_cell_info = processed_suite2p_dir+'/plane'+str(p_i)+'/DeltaF_F/cell_info_'+fish_str+'_plane'+str(p_i)+'.csv')\n",
    "        df_cell_info = pd.read_csv(path_cell_info)\n",
    "        \n",
    "        if np.array_equiv(np.array(df_cell_info['ROI_id']),np.array(df_csv_reg3d['label'])):\n",
    "            df_cell_info['reg_x'] = df_csv_reg3d['x']\n",
    "            df_cell_info['reg_y'] = df_csv_reg3d['y']\n",
    "            df_cell_info['reg_z'] = df_csv_reg3d['z']\n",
    "        else:\n",
    "            print('error when writing '+path_csv_reg3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3a1a5",
   "metadata": {},
   "source": [
    "## Step 4.6 (No Code but important!!!) Check the registration performance by examining registered position of landmark cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
